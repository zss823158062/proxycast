//! 模型注册表数据结构
//!
//! 借鉴 opencode 的模型管理方式，定义增强的模型元数据结构

use serde::{Deserialize, Serialize};

/// 模型能力
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct ModelCapabilities {
    /// 是否支持视觉输入
    pub vision: bool,
    /// 是否支持工具调用
    pub tools: bool,
    /// 是否支持流式输出
    pub streaming: bool,
    /// 是否支持 JSON 模式
    pub json_mode: bool,
    /// 是否支持函数调用
    pub function_calling: bool,
    /// 是否支持推理/思考
    pub reasoning: bool,
}

/// 模型定价
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelPricing {
    /// 输入价格（每百万 token）
    pub input_per_million: Option<f64>,
    /// 输出价格（每百万 token）
    pub output_per_million: Option<f64>,
    /// 缓存读取价格（每百万 token）
    pub cache_read_per_million: Option<f64>,
    /// 缓存写入价格（每百万 token）
    pub cache_write_per_million: Option<f64>,
    /// 货币单位 ("USD" | "CNY")
    pub currency: String,
}

impl Default for ModelPricing {
    fn default() -> Self {
        Self {
            input_per_million: None,
            output_per_million: None,
            cache_read_per_million: None,
            cache_write_per_million: None,
            currency: "USD".to_string(),
        }
    }
}

/// 模型限制
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct ModelLimits {
    /// 上下文长度
    pub context_length: Option<u32>,
    /// 最大输出 token 数
    pub max_output_tokens: Option<u32>,
    /// 每分钟请求数限制
    pub requests_per_minute: Option<u32>,
    /// 每分钟 token 数限制
    pub tokens_per_minute: Option<u32>,
}

/// 模型状态
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum ModelStatus {
    /// 活跃可用
    Active,
    /// 预览版
    Preview,
    /// Alpha 测试
    Alpha,
    /// Beta 测试
    Beta,
    /// 已弃用
    Deprecated,
    /// 旧版本
    Legacy,
}

impl Default for ModelStatus {
    fn default() -> Self {
        Self::Active
    }
}

impl std::fmt::Display for ModelStatus {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Active => write!(f, "active"),
            Self::Preview => write!(f, "preview"),
            Self::Alpha => write!(f, "alpha"),
            Self::Beta => write!(f, "beta"),
            Self::Deprecated => write!(f, "deprecated"),
            Self::Legacy => write!(f, "legacy"),
        }
    }
}

impl std::str::FromStr for ModelStatus {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "active" => Ok(Self::Active),
            "preview" => Ok(Self::Preview),
            "alpha" => Ok(Self::Alpha),
            "beta" => Ok(Self::Beta),
            "deprecated" => Ok(Self::Deprecated),
            "legacy" => Ok(Self::Legacy),
            _ => Err(format!("Unknown model status: {}", s)),
        }
    }
}

/// 模型服务等级
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum ModelTier {
    /// 快速响应，适合简单任务
    Mini,
    /// 均衡性能，适合大多数任务
    Pro,
    /// 最强能力，适合复杂任务
    Max,
}

impl Default for ModelTier {
    fn default() -> Self {
        Self::Pro
    }
}

impl std::fmt::Display for ModelTier {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Mini => write!(f, "mini"),
            Self::Pro => write!(f, "pro"),
            Self::Max => write!(f, "max"),
        }
    }
}

impl std::str::FromStr for ModelTier {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "mini" => Ok(Self::Mini),
            "pro" => Ok(Self::Pro),
            "max" => Ok(Self::Max),
            _ => Err(format!("Unknown model tier: {}", s)),
        }
    }
}

/// 模型数据来源
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum ModelSource {
    /// 从 models.dev API 获取
    ModelsDev,
    /// 本地硬编码（国内模型等）
    Local,
    /// 用户自定义
    Custom,
}

impl Default for ModelSource {
    fn default() -> Self {
        Self::Local
    }
}

impl std::fmt::Display for ModelSource {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::ModelsDev => write!(f, "models.dev"),
            Self::Local => write!(f, "local"),
            Self::Custom => write!(f, "custom"),
        }
    }
}

impl std::str::FromStr for ModelSource {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "models.dev" | "modelsdev" => Ok(Self::ModelsDev),
            "local" => Ok(Self::Local),
            "custom" => Ok(Self::Custom),
            _ => Err(format!("Unknown model source: {}", s)),
        }
    }
}

/// 增强的模型元数据
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EnhancedModelMetadata {
    /// 模型 ID (如 "claude-sonnet-4-5-20250514")
    pub id: String,
    /// 显示名称 (如 "Claude Sonnet 4.5")
    pub display_name: String,
    /// Provider ID (如 "anthropic", "openai", "dashscope")
    pub provider_id: String,
    /// Provider 显示名称
    pub provider_name: String,
    /// 模型家族 (如 "sonnet", "gpt-4", "qwen")
    pub family: Option<String>,
    /// 服务等级
    pub tier: ModelTier,
    /// 模型能力
    pub capabilities: ModelCapabilities,
    /// 定价信息
    pub pricing: Option<ModelPricing>,
    /// 限制信息
    pub limits: ModelLimits,
    /// 模型状态
    pub status: ModelStatus,
    /// 发布日期
    pub release_date: Option<String>,
    /// 是否为最新版本
    pub is_latest: bool,
    /// 描述
    pub description: Option<String>,
    /// 数据来源
    pub source: ModelSource,
    /// 创建时间 (Unix 时间戳)
    pub created_at: i64,
    /// 最后更新时间 (Unix 时间戳)
    pub updated_at: i64,
}

impl EnhancedModelMetadata {
    /// 创建新的模型元数据
    pub fn new(
        id: String,
        display_name: String,
        provider_id: String,
        provider_name: String,
    ) -> Self {
        let now = chrono::Utc::now().timestamp();
        Self {
            id,
            display_name,
            provider_id,
            provider_name,
            family: None,
            tier: ModelTier::Pro,
            capabilities: ModelCapabilities::default(),
            pricing: None,
            limits: ModelLimits::default(),
            status: ModelStatus::Active,
            release_date: None,
            is_latest: false,
            description: None,
            source: ModelSource::Local,
            created_at: now,
            updated_at: now,
        }
    }

    /// 设置模型家族
    pub fn with_family(mut self, family: impl Into<String>) -> Self {
        self.family = Some(family.into());
        self
    }

    /// 设置服务等级
    pub fn with_tier(mut self, tier: ModelTier) -> Self {
        self.tier = tier;
        self
    }

    /// 设置模型能力
    pub fn with_capabilities(mut self, capabilities: ModelCapabilities) -> Self {
        self.capabilities = capabilities;
        self
    }

    /// 设置定价信息
    pub fn with_pricing(mut self, pricing: ModelPricing) -> Self {
        self.pricing = Some(pricing);
        self
    }

    /// 设置限制信息
    pub fn with_limits(mut self, limits: ModelLimits) -> Self {
        self.limits = limits;
        self
    }

    /// 设置模型状态
    pub fn with_status(mut self, status: ModelStatus) -> Self {
        self.status = status;
        self
    }

    /// 设置发布日期
    pub fn with_release_date(mut self, date: impl Into<String>) -> Self {
        self.release_date = Some(date.into());
        self
    }

    /// 设置是否为最新版本
    pub fn with_is_latest(mut self, is_latest: bool) -> Self {
        self.is_latest = is_latest;
        self
    }

    /// 设置描述
    pub fn with_description(mut self, description: impl Into<String>) -> Self {
        self.description = Some(description.into());
        self
    }

    /// 设置数据来源
    pub fn with_source(mut self, source: ModelSource) -> Self {
        self.source = source;
        self
    }
}

/// 用户模型偏好
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserModelPreference {
    /// 模型 ID
    pub model_id: String,
    /// 是否收藏
    pub is_favorite: bool,
    /// 是否隐藏
    pub is_hidden: bool,
    /// 自定义别名
    pub custom_alias: Option<String>,
    /// 使用次数
    pub usage_count: u32,
    /// 最后使用时间 (Unix 时间戳)
    pub last_used_at: Option<i64>,
    /// 创建时间 (Unix 时间戳)
    pub created_at: i64,
    /// 更新时间 (Unix 时间戳)
    pub updated_at: i64,
}

impl UserModelPreference {
    /// 创建新的用户偏好
    pub fn new(model_id: String) -> Self {
        let now = chrono::Utc::now().timestamp();
        Self {
            model_id,
            is_favorite: false,
            is_hidden: false,
            custom_alias: None,
            usage_count: 0,
            last_used_at: None,
            created_at: now,
            updated_at: now,
        }
    }
}

/// 模型同步状态
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelSyncState {
    /// 最后同步时间 (Unix 时间戳)
    pub last_sync_at: Option<i64>,
    /// 同步的模型数量
    pub model_count: u32,
    /// 是否正在同步
    pub is_syncing: bool,
    /// 最后同步错误
    pub last_error: Option<String>,
}

impl Default for ModelSyncState {
    fn default() -> Self {
        Self {
            last_sync_at: None,
            model_count: 0,
            is_syncing: false,
            last_error: None,
        }
    }
}

/// models.dev API 响应中的 Provider 结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelsDevProvider {
    pub id: String,
    pub name: String,
    #[serde(default)]
    pub api: Option<String>,
    #[serde(default)]
    pub npm: Option<String>,
    #[serde(default)]
    pub models: std::collections::HashMap<String, ModelsDevModel>,
}

/// models.dev API 响应中的 Model 结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelsDevModel {
    pub id: String,
    pub name: String,
    #[serde(default)]
    pub family: Option<String>,
    #[serde(default)]
    pub release_date: Option<String>,
    #[serde(default)]
    pub attachment: bool,
    #[serde(default)]
    pub reasoning: bool,
    #[serde(default)]
    pub temperature: bool,
    #[serde(default)]
    pub tool_call: bool,
    #[serde(default)]
    pub cost: Option<ModelsDevCost>,
    #[serde(default)]
    pub limit: Option<ModelsDevLimit>,
    #[serde(default)]
    pub modalities: Option<ModelsDevModalities>,
    #[serde(default)]
    pub experimental: Option<bool>,
    #[serde(default)]
    pub status: Option<String>,
}

/// models.dev API 响应中的 Cost 结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelsDevCost {
    #[serde(default)]
    pub input: Option<f64>,
    #[serde(default)]
    pub output: Option<f64>,
    #[serde(default)]
    pub cache_read: Option<f64>,
    #[serde(default)]
    pub cache_write: Option<f64>,
}

/// models.dev API 响应中的 Limit 结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelsDevLimit {
    #[serde(default)]
    pub context: Option<u32>,
    #[serde(default)]
    pub output: Option<u32>,
}

/// models.dev API 响应中的 Modalities 结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelsDevModalities {
    #[serde(default)]
    pub input: Vec<String>,
    #[serde(default)]
    pub output: Vec<String>,
}

impl ModelsDevModel {
    /// 转换为 EnhancedModelMetadata
    pub fn to_enhanced_metadata(
        &self,
        provider_id: &str,
        provider_name: &str,
    ) -> EnhancedModelMetadata {
        let now = chrono::Utc::now().timestamp();

        // 判断是否支持视觉
        let supports_vision = self
            .modalities
            .as_ref()
            .map(|m| m.input.iter().any(|i| i == "image" || i == "video"))
            .unwrap_or(false)
            || self.attachment;

        // 根据模型名称推断服务等级
        let tier = infer_model_tier(&self.id, &self.name);

        // 解析状态
        let status = self
            .status
            .as_ref()
            .and_then(|s| s.parse().ok())
            .unwrap_or(ModelStatus::Active);

        // 判断是否为最新版本
        let is_latest = self.id.contains("latest");

        EnhancedModelMetadata {
            id: self.id.clone(),
            display_name: self.name.clone(),
            provider_id: provider_id.to_string(),
            provider_name: provider_name.to_string(),
            family: self.family.clone(),
            tier,
            capabilities: ModelCapabilities {
                vision: supports_vision,
                tools: self.tool_call,
                streaming: true, // 大多数模型都支持流式
                json_mode: true, // 大多数模型都支持 JSON 模式
                function_calling: self.tool_call,
                reasoning: self.reasoning,
            },
            pricing: self.cost.as_ref().map(|c| ModelPricing {
                input_per_million: c.input,
                output_per_million: c.output,
                cache_read_per_million: c.cache_read,
                cache_write_per_million: c.cache_write,
                currency: "USD".to_string(),
            }),
            limits: ModelLimits {
                context_length: self.limit.as_ref().and_then(|l| l.context),
                max_output_tokens: self.limit.as_ref().and_then(|l| l.output),
                requests_per_minute: None,
                tokens_per_minute: None,
            },
            status,
            release_date: self.release_date.clone(),
            is_latest,
            description: None,
            source: ModelSource::ModelsDev,
            created_at: now,
            updated_at: now,
        }
    }
}

/// 根据模型 ID 和名称推断服务等级
fn infer_model_tier(model_id: &str, model_name: &str) -> ModelTier {
    let id_lower = model_id.to_lowercase();
    let name_lower = model_name.to_lowercase();

    // Max 等级模型
    let max_patterns = [
        "opus",
        "gpt-4o",
        "gpt-4-turbo",
        "gemini-2.5-pro",
        "gemini-ultra",
        "claude-3-opus",
        "qwen-max",
        "glm-4-plus",
        "deepseek-v3",
    ];
    for pattern in max_patterns {
        if id_lower.contains(pattern) || name_lower.contains(pattern) {
            return ModelTier::Max;
        }
    }

    // Mini 等级模型
    let mini_patterns = [
        "mini",
        "nano",
        "lite",
        "flash",
        "haiku",
        "gpt-4o-mini",
        "gemini-flash",
        "qwen-turbo",
        "glm-4-flash",
    ];
    for pattern in mini_patterns {
        if id_lower.contains(pattern) || name_lower.contains(pattern) {
            return ModelTier::Mini;
        }
    }

    // 默认为 Pro 等级
    ModelTier::Pro
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_model_tier_inference() {
        assert_eq!(
            infer_model_tier("claude-opus-4-5-20250514", "Claude Opus 4.5"),
            ModelTier::Max
        );
        assert_eq!(
            infer_model_tier("gpt-4o-mini", "GPT-4o Mini"),
            ModelTier::Mini
        );
        assert_eq!(
            infer_model_tier("claude-sonnet-4-5", "Claude Sonnet 4.5"),
            ModelTier::Pro
        );
        assert_eq!(
            infer_model_tier("gemini-2.5-flash", "Gemini 2.5 Flash"),
            ModelTier::Mini
        );
    }

    #[test]
    fn test_model_status_parsing() {
        assert_eq!(
            "active".parse::<ModelStatus>().unwrap(),
            ModelStatus::Active
        );
        assert_eq!(
            "deprecated".parse::<ModelStatus>().unwrap(),
            ModelStatus::Deprecated
        );
        assert_eq!("beta".parse::<ModelStatus>().unwrap(), ModelStatus::Beta);
    }
}
